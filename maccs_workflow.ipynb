{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python standard library\n",
    "import os, sys\n",
    "\n",
    "# Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, WhiteKernel\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Utils\n",
    "sys.path.append(\".\")\n",
    "from utils import classification_metrics as cmetrics\n",
    "from utils import finger_prints as fp\n",
    "from utils import classification_workflow_functions as cwf\n",
    "\n",
    "import logging \n",
    "logging.basicConfig(format='%(message)s')\n",
    "log = logging.getLogger()\n",
    "log.setLevel(logging.ERROR)\n",
    "\n",
    "from dask.distributed import Client\n",
    "try:\n",
    "    client.shutdown()\n",
    "except NameError:\n",
    "    log.info(\"No client already active\")\n",
    "\n",
    "client = Client(dashboard_address=\":8855\")\n",
    "log.info(\"Dask clinet on localhost:8855\")\n",
    "\n",
    "random_seed = 10459\n",
    "np.random.seed = random_seed\n",
    "np.random.RandomState(random_seed)\n",
    "log.info(f\"Random seed fixed as {random_seed} current working dir {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"results_maccs_keys\", exist_ok=True)\n",
    "os.chdir(\"results_maccs_keys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/ccs-98.csv\", sep=\";\")\n",
    "data.columns = [\"_\".join(ent.lower().strip().split(\" \")) for ent in data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = data[\"smiles\"]\n",
    "log.info(\"SMILES: {}\".format(smiles.head()))\n",
    "\n",
    "names = data[\"label\"]\n",
    "log.info(\"Names: {}\".format(names.head()))\n",
    "\n",
    "number_of_n_atoms = data[\"n_nitrogen\"].astype(\"int\")\n",
    "log.info(\"Number of N atoms: {}\".format(number_of_n_atoms.head()))\n",
    "\n",
    "amines_mass_mr = data[\"molecular_mass\"].astype(\"float64\")\n",
    "pd.to_numeric(amines_mass_mr, errors=\"coerce\")\n",
    "log.info(\"Amines mass Mr: {}\".format(amines_mass_mr.head()))\n",
    "\n",
    "molco2_moln = data[\"capacity_molco2_molamime\"]\n",
    "pd.to_numeric(molco2_moln, errors=\"coerce\")\n",
    "log.info(\"molCO2_molN: {}\".format(molco2_moln.head()))\n",
    "\n",
    "initial_rates = data[\"rate_molco2_molamime_min\"]\n",
    "pd.to_numeric(initial_rates, errors=\"coerce\")\n",
    "log.info(\"initial_rates: {}\".format(initial_rates.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Target Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = molco2_moln\n",
    "target_name = \"capacity (molCO2 / molN)\"\n",
    "target_key = \"capacity_molco2_molamime\"\n",
    "units = \"molco2_moln\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fp.maccskeys_fingerprints(smiles)\n",
    "features = [list(fp.ToBitString()) for fp in features]\n",
    "features_df = pd.DataFrame(data=np.array(features))\n",
    "features_df.columns = [\"MACCS_bit_{}\".format(i) for i in range(len(features_df.columns))]\n",
    "features_df = features_df.astype('int32')\n",
    "#features_fp_df = pd.DataFrame(data=np.array([\"\".join([str(i) for i in row.values]) for index, row in features_df.iterrows()]).T, columns=[\"ccs_fingerprints\"])\n",
    "log.info(features_df)\n",
    "#feature_types = \"catagorical\" # other options 'some_catagorical', 'no_catagorical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log.info(\"\\n\".join([\"\".join([str(i) for i in row.values]) for index, row in features_df.iterrows()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.to_csv(\"maccs_fingerprints.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts = []\n",
    "for ith, s in enumerate(smiles):\n",
    "    n_primary, n_secondary, n_tertiary, n_aromaticsp2 = cwf.count_amine_types(s, show=False)\n",
    "    counts.append([n_primary, n_secondary, n_tertiary, n_aromaticsp2])\n",
    "    log.debug(\"\\n{}; number of primary: {} number of secondary: {} number of tertiary: {} number of aromatic sp2 nitrogen atoms: {}\\nsmiles {}\". format(ith, n_primary, n_secondary, n_tertiary, n_aromaticsp2, s))\n",
    "\n",
    "df = pd.DataFrame(data=counts, columns=[\"primary_amine_counts\",\"secondary_amine_counts\", \"tertiary_amine_counts\", \"aromatic_sp2_n\" ])\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if target_name == \"initial_rate\":\n",
    "    log.info(\"Initial rate class\")\n",
    "    mean = np.mean(initial_rates)\n",
    "    stdev = np.std(initial_rates)\n",
    "    class_thresh = mean + stdev\n",
    "    log.info(\"mean {} standard deviation {} class threshold {}\".format(mean, stdev, class_thresh))\n",
    "    classes = []\n",
    "    for i in initial_rates:\n",
    "        if i < class_thresh:\n",
    "            classes.append(0)\n",
    "        else:\n",
    "            classes.append(1)\n",
    "    log.info(\"Number of classes: {}  Number of class 1: {} number of class 0: {}\".format(len(classes), len([x for x in classes if x == 1]), len([x for x in classes if x == 0])))\n",
    "    class_targets_df = pd.DataFrame(np.array([classes]).T, columns=[\"classes\"])\n",
    "    features_and_classes_df = features_df.copy()\n",
    "    features_and_classes_df[\"classes\"] = classes\n",
    "    \n",
    "else:\n",
    "    log.info(\"Capture capacity class\")\n",
    "    classes = cwf.capacity_classes(df[\"primary_amine_counts\"].values, df[\"secondary_amine_counts\"].values, df[\"tertiary_amine_counts\"].values, df[\"aromatic_sp2_n\"].values, targets,\n",
    "                         units=units, number_N_atoms=number_of_n_atoms, amines_mr=amines_mass_mr)\n",
    "    log.info(classes)\n",
    "    log.info(\"Number of classes: {}  Number of class 1: {} number of class 0: {}\".format(len(classes), len([x for x in classes if x == 1]), len([x for x in classes if x == 0])))\n",
    "\n",
    "    class_targets_df = pd.DataFrame(np.array([classes]).T, columns=[\"classes\"])\n",
    "    features_and_classes_df = features_df.copy()\n",
    "    features_and_classes_df[\"classes\"] = classes\n",
    "    \n",
    "feature_types = \"catagorical\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_clf_names = [\"AdaBoost\",\"Logistic Regression\", \"Gaussian Process\"]\n",
    "\n",
    "kfold_classifiers = [\n",
    "    AdaBoostClassifier(random_state=random_seed),\n",
    "    LogisticRegression(random_state=random_seed, n_jobs=-1, solver=\"lbfgs\"), \n",
    "    GaussianProcessClassifier(random_state=random_seed, n_jobs=-1),\n",
    "]\n",
    "\n",
    "kfold_classifier_parameters = {\n",
    "    \"AdaBoost\": {\"n_estimators\": [10, 20, 50, 100]},\n",
    "    \"Logistic Regression\": {\"penalty\":[\"l2\"], \"C\": [0.05, 0.1, 0.25, 0.5, 1.0, 1.25]},\n",
    "    \"Gaussian Process\": {\"kernel\":[1.0 * Matern(length_scale=1.0, nu=1.5), 1.0 * Matern(length_scale=1.0, nu=2.5), 1.0 * RBF(1.0),  1.0 * RBF(1.0) + WhiteKernel(noise_level=0.5)]},\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_df = pd.DataFrame(data=classes, columns=[\"classes\"])\n",
    "log.info(\"Number in class 0: {}\\nNumber in class 1: {}\\nNumber of examples: {}\".format(\n",
    "    len([ith for ith in classes if ith == 0]), \n",
    "    len([ith for ith in classes if ith == 1]), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwf.kfold_test_imbalenced_classifiers_with_optimization(features_df, classes_df, kfold_classifiers, kfold_classifier_parameters, \n",
    "                                                        overwrite=True, scale=False, cv=10, n_repeats=5, smiles=smiles, names=names,\n",
    "                                                        random_seed=random_seed, clf_names=kfold_clf_names, class_labels=(0,1),\n",
    "                                                        smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_clf_names = [\"AdaBoost\",\"Logistic Regression\", \"Gaussian Process\"]\n",
    "directory_names = cwf.directory_names_from_classfier_names(kfold_clf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_plt = []\n",
    "\n",
    "kfold_clf_names = [\"AdaBoost\",\n",
    "         \"Logistic Regression\"]\n",
    "\n",
    "for ith, dirname in enumerate(directory_names):\n",
    "    log.info(\"\\n{}\\n-------------\\n\".format(dirname))\n",
    "    data = cwf.build_data_from_directory(dirname, max_folds=5)\n",
    "    data.to_csv(\"{}_cv_predictions.csv\".format(\"_\".join(dirname.split()), index=False))\n",
    "    log.debug(\"Last value in the data frame: {}\".format(data[165:166]))\n",
    "    \n",
    "    probs = data[[\"prob0\", \"prob1\"]].to_numpy()\n",
    "    log.debug(\"Probablities for a few examples {}\".format(probs[0:3,0:2]))\n",
    "    \n",
    "    cm = cmetrics.get_confusion_matrix(data, predicted_column_name=\"prediction\", known_column_name=\"known\", return_dict=False)\n",
    "    log.debug(\"Confusion matrix for {}\\n{}\".format(dirname, cm))\n",
    "    \n",
    "    plt_name = \"capacity_{}_fingerprints.png\".format(\"_\".join([ent.lower() for ent in dirname.split()]))\n",
    "    files_plt.append(plt_name)\n",
    "    log.info(\"Saving plot to {}\\n{}\".format(plt_name, files_plt))\n",
    "    metrics = cmetrics.calculate_confusion_based_metrics(df=data, probabilities=probs, col_map=\"hsv\", positive_label=1, \n",
    "                                                         plt_filename=plt_name, all_classes=False, get_roc_curve=True, \n",
    "                                                         get_pr_curve=False, annotate=True, vmin=0, vmax=85,\n",
    "                                                         title=\"{}\".format(kfold_clf_names[ith]),)\n",
    "    #log.info(\"{}\".format(\"\\n\".join([\"{}: {}\".format(k, v) for k, v in metrics.items()])))\n",
    "    \n",
    "    metrics_for_paper = {\n",
    "        \"accuracy\": metrics[\"accuracy\"],\n",
    "        \"sensitivity\": metrics[\"tpr\"],\n",
    "        \"specificity\": metrics[\"tnr\"],\n",
    "        \"mcc\": metrics[\"matthews_correlation_coefficient\"],\n",
    "\n",
    "        }\n",
    "    \n",
    "    if ith == 0:\n",
    "        df_metrics_for_paper = pd.DataFrame(data=metrics_for_paper, index=[kfold_clf_names[ith].lower()])\n",
    "    else:\n",
    "        df_metrics_for_paper = df_metrics_for_paper.append(pd.Series(metrics_for_paper, name=kfold_clf_names[ith].lower()))\n",
    "    log.debug(df_metrics_for_paper)\n",
    "\n",
    "with open(\"capacity_metrics_fingerprints.tex\", \"w\") as fout:\n",
    "    cap = \"Classifier metrics for balanced data for capacity with models built from fingerprint features. MCC is the Matthew’s correlation coefficent.\"\n",
    "    df_metrics_for_paper.to_latex(fout, float_format=\"{:0.2f}\".format, position=\"H\", caption=cap, label=\"tbl:fingerprint_features\")\n",
    "log.info(df_metrics_for_paper.to_latex())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fimp = pd.read_csv(\"importance_lr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fimp_mean = fimp.mean(axis=0)\n",
    "means = fimp_mean.values\n",
    "fimp_means = pd.DataFrame(means).transpose()\n",
    "fimp_means.columns=features_df.columns\n",
    "\n",
    "fimp_sigma = fimp.std(axis=0)\n",
    "sigmas = fimp_sigma.values\n",
    "fimp_sigmas = pd.DataFrame(sigmas).transpose()\n",
    "fimp_sigmas.columns=features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(60,20))\n",
    "plt.bar(x=[\" \".join(ent.split(\"_\")) for ent in fimp_means.columns], \n",
    "        height=fimp_means.iloc[0,:].values, \n",
    "        width=1.0,\n",
    "        edgecolor=\"k\",\n",
    "        align=\"edge\")\n",
    "bins = np.arange(len(fimp_means.columns))\n",
    "plt.xlim([0,bins.size])\n",
    "plt.xlabel(\"Feature\", fontsize=35)\n",
    "plt.ylabel(\"Mean Coefficent value\", fontsize=35)\n",
    "plt.xticks(rotation=90, fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.title(\"Logistic Regression Mean Feature Importance using MACCS keys\", fontsize=35)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"feature_importance_lr_ccs.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
